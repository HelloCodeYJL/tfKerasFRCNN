{"cells":[{"cell_type":"markdown","source":[" # If using Colab"],"metadata":{}},{"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# import os\n","# os.chdir('/content/drive/My Drive/Colab Notebooks/ISY5004')\n","# print(os.getcwd())\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # Configuration"],"metadata":{}},{"source":["import math\n","baseModelName = \"FRCNN\"\n","base_net_type = 'vgg'   # either 'vgg' or 'resnet50'\n","modelName = baseModelName + \"_\" + base_net_type\n","model_path = modelName + \".hdf5\"\n","csv_path = modelName + \".csv\"\n","\n","num_epochs = 40\n","\n","im_size = 300                       # shorter-side length. Original is 600, half it to save training time\n","anchor_box_scales = [64,128,256]    # also half box_scales accordingly. Original is [128,256,512]\n","anchor_box_ratios = [[1,1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]] # anchor box ratios area == 1\n","num_rois = 4\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # Load data"],"metadata":{}},{"source":["from FRCNN import parseAnnotationFile\n","annotation_train_path = './annotation_train.txt'\n","train_data, classes_count, class_mapping = parseAnnotationFile(annotation_train_path)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## Inspect annotation file with a sample image"],"metadata":{}},{"source":["from FRCNN import viewAnnotatedImage\n","viewAnnotatedImage(annotation_train_path, 'resize/train/image100.jpg', class_mapping)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # Create and Train FRCNN model"],"metadata":{}},{"cell_type":"markdown","source":[" ## Create"],"metadata":{}},{"source":["from FRCNN import FRCNN\n","num_anchors = len(anchor_box_scales) * len(anchor_box_ratios)\n","frcnn = FRCNN(input_shape=(None,None,3), num_anchors=num_anchors, num_rois=num_rois, base_net_type=base_net_type, num_classes = len(classes_count))\n","frcnn.compile()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## Visualise"],"metadata":{}},{"source":["frcnn.model_rpn.summary()\n","frcnn.summary()\n","\n","# Plot structure of FRCNN\n","from tensorflow.keras.utils import plot_model\n","plot_model(frcnn.model_all, to_file=modelName+'.png', show_shapes=True, show_layer_names=False, rankdir='TB')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## Train"],"metadata":{}},{"source":["## create iterator\n","from FRCNN import FRCNNGenerator, inspect\n","train_it = FRCNNGenerator(train_data,\n","    target_size= im_size, std_scaling=4,\n","    horizontal_flip=True, vertical_flip = False, rotation_range = 0, shuffle=False, base_net_type=base_net_type\n",")\n","\n","inspect(train_it, im_size)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# train model - will automatically resume training if csv and model already exists\n","frcnn.fit_generator(train_it, target_size = im_size, class_mapping = class_mapping, epochs=num_epochs, model_path=model_path, csv_path=csv_path)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # Examine Performance"],"metadata":{}},{"cell_type":"markdown","source":[" # Test FRCNN model"],"metadata":{}},{"source":["model_path = \"FRCNN_vgg.hdf5\"\n","base_net_type = 'vgg'\n","im_size = 300                       # shorter-side length. Original is 600, half it to save training time\n","anchor_box_scales = [64,128,256]    # also half box_scales accordingly. Original is [128,256,512]\n","anchor_box_ratios = [[1,1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]] # anchor box ratios area == 1\n","num_rois = 4\n","num_anchors = len(anchor_box_scales) * len(anchor_box_ratios)\n","\n","# Load image information\n","from FRCNN import parseAnnotationFile\n","annotation_train_path = './annotation_train.txt'\n","train_data, classes_count, class_mapping = parseAnnotationFile(annotation_train_path)\n","\n","annotation_test_path = './annotation_test.txt'\n","test_data, _ , _ = parseAnnotationFile(annotation_test_path)\n","\n","\n","# Create model and load trained weights (Note: class mapping and num_classes should be based on training set)\n","from FRCNN import FRCNN\n","frcnn_test = FRCNN(input_shape=(None,None,3), num_anchors=num_anchors, num_rois=num_rois, base_net_type=base_net_type, num_classes = len(classes_count))\n","frcnn_test.load_config(anchor_box_scales=anchor_box_scales, anchor_box_ratios=anchor_box_ratios, num_rois=num_rois, target_size=im_size)\n","frcnn_test.load_weights(model_path)\n","frcnn_test.compile()\n","\n","# Load array of images\n","from FRCNN import convertDataToImg\n","test_imgs = convertDataToImg(test_data)\n","\n","# Perform predictions\n","predicts = frcnn_test.predict(test_imgs, class_mapping=class_mapping, verbose=1)\n","\n","\n","# evaluate = frcnn_test.evaluate()\n","\n","# labelname = list(test_it.class_indices.keys())\n","# predout = np.argmax(predicts, axis = 1)\n","# scores = metrics.accuracy_score(test_it.labels, predout)\n","# confusion = metrics.confusion_matrix(test_it.labels, predout)\n","\n","# print(\"Best accuracy (on test dataset): %.2f%%\" % (scores*100))\n","# print(metrics.classification_report(test_it.labels, predout, target_names=labelname, digits=4 ))\n","# print(confusion)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}